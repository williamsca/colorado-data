# This script imports and appends the valuation data
# generated by Amazon Textract.

rm(list = ls())
library(here)
library(data.table)
library(readxl)
library(stringr)

# import ----
l_files <- list.files(
    path = here("derived", "county-valuation"),
    pattern = "*.xlsx",
    full.names = TRUE
)

file_path <- l_files[1]

process_valuation_file <- function(file_path) {
    filename <- basename(file_path)
    year <- as.numeric(str_extract(filename, "^\\d{4}"))

    dt <- as.data.table(read_xlsx(file_path, col_names = FALSE))
    dt[, year := year]

    setnames(dt, "...1", "county")
    dt[, county := str_to_title(str_trim(gsub("\\$|\\*|\\s+$", "", county)))]

    dt <- dt[!grepl("(?i)(total|state|average)", county)]

    if (!"residential_1000" %in% names(dt)) {
        warning(paste("No residential valuation column found in", filename))
        return(NULL)
    }

    v_num <- c("residential_1000", "assessed_total")
    if (!all(v_num %in% names(dt))) {
        warning(paste("Missing columns in", filename))
        print(paste0("Columns in data: ", names(dt)))
        return(NULL)
    }
    dt[, (v_num) := lapply(.SD, function(x) {
        as.numeric(gsub(",|\\$|\\.", "", x))
    }), .SDcols = v_num]
    if (year >= 1987) { # TODO: check this year
        dt[, (v_num) := lapply(.SD, function(x) {
            x * 1000
        }), .SDcols = v_num]
    }

    dt <- dt[, .(county, year, residential_1000, assessed_total)]
}

# 3. Process all files and combine results
dt_val <- rbindlist(
    lapply(l_files, process_valuation_file),
    use.names = TRUE,
    fill = TRUE
)

dt_val <- dt_val[!is.na(county) & !is.na(county_mill_levy)]

dt_val[, county := gsub(" \\+|:|'| #| 4", "", county)]
dt_val[county == "Adass", county := "Adams"]
dt_val[county == "Alasosa" | county == "Alomoso", county := "Alamosa"]
dt_val[county == "Archufeta" | county == "Archuteta", county := "Archuleta"]
dt_val[county == "Baco", county := "Baca"]
dt_val[county == "Costillo", county := "Costilla"]
dt_val[, county := gsub("E1", "El", county)]
dt_val[county == "Paso", county := "El Paso"]
dt_val[county == "Layle", county := "Eagle"]
dt_val[county == "Fresont", county := "Fremont"]
dt_val[county == "Gorfield" | county == "Carfield", county := "Garfield"]
dt_val[county == "Sunnison", county := "Gunnison"]
dt_val[county == "Gr And", county := "Grand"]
dt_val[
    county %in% c("Huefrano", "Huer Fano", "Huerfand", "Huerfono"),
    county := "Huerfano"
]
dt_val[county == "Lariser", county := "Larimer"]
dt_val[county == "Las Anieas", county := "Las Animas"]
dt_val[county == "Montezuea", county := "Montezuma"]
dt_val[county == "Borgan", county := "Morgan"]
dt_val[county == "Promers", county := "Prowers"]
dt_val[county == "Pueble", county := "Pueblo"]
dt_val[
    county == "R10 Grande" | county == "Rio Brande",
    county := "Rio Grande"
]
dt_val[county == "Suemit", county := "Summit"]
dt_val[county == "Sussit", county := "Summit"]
dt_val[county == "Utero", county := "Otero"]
dt_val[county == "Duray", county := "Ouray"]
dt_val[county == "Yuna", county := "Yuma"]

table(dt_val$county)

# 4. Validate the data
# Check for missing values
missing_counties <- dt_val[is.na(county), .N]
missing_levies <- dt_val[is.na(county_mill_levy), .N]

if (missing_counties > 0) {
    warning(paste("Missing county names:", missing_counties))
}

if (missing_levies > 0) {
    warning(paste("Missing valuation values:", missing_levies))
}

# Check for duplicates
if (uniqueN(dt_val[, .(county, year)]) != nrow(dt_val)) {
    warning("Mill levy data contains duplicates")
}

# Export ----
saveRDS(dt_val, file = here("derived", "county-valuations.Rds"))

